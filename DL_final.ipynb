{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f33c9c2",
   "metadata": {},
   "source": [
    "Download dataset from TTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71593882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from TTS.utils.downloaders import download_vctk\n",
    "\n",
    "output_path = os.getcwd()\n",
    "dataset_path = os.path.join(output_path, \"../VCTK/\")\n",
    "\n",
    "#download_vctk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda4f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c0aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from encoder.preprocess import preprocess_vctk\n",
    "import numpy as np\n",
    "import torch\n",
    "from synthesizer.inference import Synthesizer\n",
    "\n",
    "\n",
    "from vocoder.inference import infer_waveform,load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing dataset \n",
    "\n",
    "datasets_root = Path(\".\")  \n",
    "out_dir = Path(\"VCTK/encoder\")  \n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Run preprocessing\n",
    "preprocess_vctk(datasets_root, out_dir, skip_existing=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca73eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"encoder2.pt\" trained to step 1564501\n"
     ]
    }
   ],
   "source": [
    "from encoder.inference import embed_utterance, load_model\n",
    "\n",
    "# Encoder model load \n",
    "# encoder2.pt is the trained weight provided by github https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Pretrained-models\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path.cwd()  # gets current working dir where the notebook runs\n",
    "weights_fpath = base_path/ \"saved_models\" / \"default\" / \"encoder2.pt\"\n",
    "\n",
    "load_model(weights_fpath=weights_fpath, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad1e2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.audio import preprocess_wav\n",
    "#transforming a new speaker audio and generate utterance \n",
    "audio_file = base_path/ \"VCTK\" / \"testing_audio.wav\"\n",
    "file = preprocess_wav(audio_file)\n",
    "utterances = embed_utterance(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1a36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Synthesizer model \n",
    "synthesizer_weight = base_path/ \"saved_models\"/\"default\"/\"synthesizer.pt\"\n",
    "model2 = Synthesizer(model_fpath=synthesizer_weight,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9746fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 30.870M\n"
     ]
    }
   ],
   "source": [
    "# giving new text & the new speaker utterance to the synthesize model to generate spectrogram\n",
    "new_text = ['Romeo, take me somewhere we can be alone  I be waiting, all that has left to do is run  You be the prince and I will be the princess  It is a love story, baby, just say, Yes']\n",
    "syn_model = model2.synthesize_spectrograms(new_text,embeddings=utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921a0959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(syn_model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df1a5f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at /home/ngtra14/DLProject/saved_models/default/vocoder.pt\n",
      "{| ████████████████ 437000/441600 | Batch Size: 46 | Gen Rate: 51.7kHz | }"
     ]
    }
   ],
   "source": [
    "# loading the vocoder model & generate the waveform for the new speaker \n",
    "from vocoder.inference import load_model\n",
    "vocoder_weight = base_path/ \"saved_models\"/\"default\"/\"vocoder.pt\"\n",
    "load_model(weights_fpath= vocoder_weight)\n",
    "generated_wave = infer_waveform(syn_model[0],normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f82582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Caught exception: PortAudioError('Error querying device -1')\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())\n",
    "try:\n",
    "    sd.stop()\n",
    "    sd.play(generated_wave, Synthesizer.sample_rate)\n",
    "except sd.PortAudioError as e:\n",
    "    print(\"\\nCaught exception: %s\" % repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3b00b",
   "metadata": {},
   "source": [
    "If Sounddevice does not work, use below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c387305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved synthesized audio as output.wav\n"
     ]
    }
   ],
   "source": [
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "waveform_int16 = np.int16(generated_wave / np.max(np.abs(generated_wave)) * 32767)\n",
    "write(\"output.wav\", Synthesizer.sample_rate, waveform_int16)\n",
    "\n",
    "print(\"Saved synthesized audio as output.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
